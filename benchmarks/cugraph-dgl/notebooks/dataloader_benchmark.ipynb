{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7656142d-e24f-4c74-99da-96b89a791a90",
   "metadata": {},
   "source": [
    "## Benchmark cuGraph vs DGL on OBGN-Products DataLoading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e4b10-c295-4b17-adff-c1d2a7c56367",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98e0ec7-32b5-4421-8004-ee8e23207a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/vjawa/miniconda3/envs/all_cuda-115_arch-x86_64/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import rmm                                                                                                                                                                                                 \n",
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "\n",
    "#TODO: Enable in torch nightly\n",
    "# torch.cuda.memory.change_current_allocator(rmm.rmm_torch_allocator)\n",
    "        \n",
    "import cugraph_dgl\n",
    "from dgl.data import AsNodePredDataset\n",
    "from dgl.dataloading import DataLoader, NeighborSampler, MultiLayerFullNeighborSampler\n",
    "from ogb.nodeproppred import DglNodePropPredDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b4743-bc69-464d-8874-3b682f5f94fc",
   "metadata": {},
   "source": [
    "### Configure if single_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc62e41-a730-4149-889f-c625504fea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81932e75-fb52-42d7-8c29-ea78376e04a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 18:58:50,778 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-01-16 18:58:50,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2023-01-16 18:58:50,875 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-01-16 18:58:50,875 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1\n",
      "libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1\n",
      "libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3\n",
      "libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3\n",
      "libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0\n",
      "libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0\n",
      "libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2\n",
      "libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2\n"
     ]
    }
   ],
   "source": [
    "if not single_gpu:\n",
    "    from dask_cuda import LocalCUDACluster\n",
    "    from dask.distributed import Client\n",
    "    import cugraph.dask.comms.comms as Comms\n",
    "    cluster = LocalCUDACluster(protocol='tcp',rmm_pool_size='25GB', CUDA_VISIBLE_DEVICES='1,2')\n",
    "    client = Client(cluster)\n",
    "    Comms.initialize(p2p=True)\n",
    "else:\n",
    "    rmm.reinitialize(pool_allocator=True, initial_pool_size=5e9, maximum_pool_size=20e9)\n",
    "    torch.cuda.memory.change_current_allocator(rmm.rmm_torch_allocator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242d8ef-2d5f-417e-b881-e699609687b2",
   "metadata": {},
   "source": [
    "## Create Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936a1782-604e-4f2e-a063-b182deaa70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AsNodePredDataset(DglNodePropPredDataset(\"ogbn-products\",root='/datasets/vjawa/gnn'))\n",
    "## Adding Self loops to make testing easier\n",
    "## As we fail with isolated edges\n",
    "## in cuGraph\n",
    "## See comment: https://github.com/rapidsai/cugraph/pull/2997\n",
    "g = dgl.add_self_loop(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa10458-53d0-4cf3-9879-f098bac352dc",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d8e4b9-6a4a-4a13-a63b-f816405d1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, g, device='cuda'):\n",
    "    train_idx = dataset.train_idx.to(device)\n",
    "    val_idx = dataset.val_idx.to(device)\n",
    "    sampler = NeighborSampler(\n",
    "        [20,20,20],# Multiple Fanout\n",
    "        prefetch_node_feats=[\"feat\"],\n",
    "        prefetch_labels=[\"label\"],\n",
    "    )\n",
    "    batch_size = 1024*20\n",
    "    train_dataloader = DataLoader(\n",
    "        g,\n",
    "        train_idx,\n",
    "        sampler,\n",
    "        device=device,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=0,\n",
    "        use_uva=False,\n",
    "    )\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c35a1e-b2bb-47df-b7ad-e740bae032d7",
   "metadata": {},
   "source": [
    "## DGL CPU Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98d6b058-632b-4917-8a27-738aa70394bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/vjawa/miniconda3/envs/all_cuda-115_arch-x86_64/lib/python3.9/site-packages/dgl/dataloading/dataloader.py:859: DGLWarning: Dataloader CPU affinity opt is not enabled, consider switching it on (see enable_cpu_affinity() or CPU best practices for DGL [https://docs.dgl.ai/tutorials/cpu/cpu_best_practises.html])\n",
      "  dgl_warning(f'Dataloader CPU affinity opt is not enabled, consider switching it on '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.69 s ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = create_dataloader(dataset, g, device='cpu')\n",
    "dataloader_it = iter(dataloader)\n",
    "# warm up\n",
    "input_nodes, output_nodes, blocks = next(dataloader_it) \n",
    "%timeit -n 5 -r 1 input_nodes, output_nodes, blocks = next(dataloader_it) \n",
    "del dataloader\n",
    "del dataloader_it\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad2714-9d86-4384-9e0a-219040b17b87",
   "metadata": {},
   "source": [
    "## DGL GPU Benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f701baf8-c96d-452e-81cc-4e4dac410b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.4 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = create_dataloader(dataset, dataset[0].to('cuda'), device='cuda')\n",
    "dataloader_it = iter(dataloader)\n",
    "# warmup\n",
    "input_nodes, output_nodes, blocks = next(dataloader_it) \n",
    "%timeit -n 5 -r 1 input_nodes, output_nodes, blocks = next(dataloader_it) \n",
    "\n",
    "del dataloader\n",
    "del dataloader_it\n",
    "del input_nodes, output_nodes, blocks\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e7e5e-2505-4055-8297-2ae79506351e",
   "metadata": {},
   "source": [
    "## cuGraph Benchmark  (features on host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a3dab8-92f7-4bb9-9fbf-a1a4170ac16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/vjawa/miniconda3/envs/all_cuda-115_arch-x86_64/lib/python3.9/site-packages/distributed/worker.py:2988: UserWarning: Large object of size 1.15 MiB detected in task graph: \n",
      "  [b'\\x98\\xb1B\\x7f\\xf0\\x7fJ\\x81\\xa8LH\\xa5\\xa3o\\xb9\\x ... =int32), False]\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.17 s ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cugraph_g = cugraph_dgl.cugraph_storage_from_heterograph(g, single_gpu=single_gpu)\n",
    "assert cugraph_g.ndata['feat']['_N'].device.type=='cpu'\n",
    "\n",
    "dataloader = create_dataloader(dataset, cugraph_g, device='cuda')\n",
    "dataloader_it = iter(dataloader)\n",
    "input_nodes, output_nodes, blocks = next(dataloader_it) \n",
    "%timeit -n 5 -r 1 input_nodes, output_nodes, blocks = next(dataloader_it) \n",
    "\n",
    "del dataloader\n",
    "del dataloader_it\n",
    "del input_nodes, output_nodes, blocks\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5657f18-2615-4b61-91c2-e67ca795e344",
   "metadata": {},
   "source": [
    "## cuGraph Benchmark  (features on device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb47386c-0256-4f1a-ad11-6e7ed1e17229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 5 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cugraph_g = cugraph_dgl.cugraph_storage_from_heterograph(g.to('cuda'), single_gpu=single_gpu)\n",
    "dataloader = create_dataloader(dataset, cugraph_g, device='cuda')\n",
    "dataloader_it = iter(dataloader)\n",
    "# warmup\n",
    "input_nodes, output_nodes, blocks = next(dataloader_it) \n",
    "%timeit -n 5 -r 1 input_nodes, output_nodes, blocks = next(dataloader_it) \n",
    "\n",
    "del dataloader\n",
    "del dataloader_it\n",
    "del input_nodes, output_nodes, blocks\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
